\chapter{Clustering Functors}
\label{chapter__clustering_functor}

In this chapter we introduce the notion of a \emph{clustering functor}.
We will use the language of category theory and build upon the discussion in section \ref{seciton__preserving_structure}, where we thought of clustering algorithms as preserving certain structures.
Ultimately, a clustering functor will be a functor, with certain properties, from a category of finite metric spaces to a category of partitions.
This construction closely follows the one by \textsc{Carlsson} and \textsc{M\'emoli} \cite{Carlsson2010}.

\section{Finite Metric Spaces}
\label{section__finite_metric_spaces}



\begin{definition}{Finite Metric Spaces \cite[Sec.~3.2]{Carlsson2010}}{}
We define three categories $\iso, \inj$ and $\gen$, all sharing the same objects:

\begin{equation*}
\ob(\M) := \{(X,d): \text{$X$ a finite non-empty set and $d$ a metric on $X$}\}
\end{equation*}

The three categories are distinguished by their morphisms. For $A, B \in \ob(\M)$ we set:
\begin{itemize}
    \item $\mor_\gen(A,B)$ the distance non-increasing functions $f: A \to B$.
    \item $\mor_\inj(A,B)$ the distance non-increasing injective functions $f: A \to B$.
    \item $\mor_\iso(A,B)$ the isometries $f: A \to B$.
\end{itemize}
The composition of morphisms is given by the composition of functions, and the identity morphism is the identity function.
\end{definition}

Depending on what kind of structures we want to preserve, we can choose one of the three categories.
By construction, we have the inclusions
\begin{equation}
    \label{eq:inclusions_of_finite_metric_space_categories}
    \iso \subset \inj \subset \gen.
\end{equation}

Furthermore, this inclusion yields functors $\iso \to \inj \to \gen$ \cite[Def.~1.2.18]{Leinster2014-dc}.
As such, $\iso$ is the category with the fewest morphisms. Indeed, between most objects there are no morphisms.
All morphisms are between spaces of the same isometry class and have an inverse.
In contrast, $\gen$ has the most morphisms. In particular, for any metric spaces $A,B \in \ob(\gen)$ we have the morphism
$$
\mathrm{const}_b: A \to B, \ a \mapsto b
$$
for some $b \in B$.

\section{Partitions and Dendrograms}
\label{section__partitions}

\begin{definition}{\todo[I think i should leave this out]}{relation}
    Let $X$ be a set, a \emph{relation} on $X$ is a subset $R \subseteq X \times X$. And we write $x R y$ if $(x,y) \in R$.
    A relation with all the following properties is called an \emph{equivalence relation}:
    \begin{enumerate}
        \item \emph{Reflexivity}: $\forall x \in X: x R x$.
        \item \emph{Symmetry}: $\forall x,y \in X: x R y \implies y R x$.
        \item \emph{Transitivity}: $\forall x,y,z \in X: x R y \text{ and } y R z \implies x R z$.
    \end{enumerate}
    In this case we will often use a symbol like $\sim$ instead of a letter like $R$ to denote the relation. The \emph{equivalence classes} of an equivalence relation $\sim$ on $X$ is the set of sets
    $$
    X/_{\sim} := \{[x]_\sim: x \in X\}
    $$
    where $[x]_\sim := \{y \in X: x \sim y\}$.
\end{definition}

\begin{definition}{Partitions of Finite Sets}{}
Let $X$ be a finite set. A partition $P$ of $X$ is the set of equivalence classes $X/_{\sim_P}$ for some equivalence relation $\sim_P$ on $X$. The set of all such partitions is denoted by $\P(X)$.\par

\medskip Furthermore:
\begin{itemize}
    \item We interchangeably use $P$ (the partition) and $\sim_P$ (the corresponding equivalence relation).
    \item A single equivalence class $X_\alpha \in P$ will be called a \emph{block} or \emph{part} of $P$.
\end{itemize}
\end{definition}

It naturally makes sense to use partitions as outputs of clustering algorithms, where a block of a partition is to be interpreted as a \emph{cluster}.

At this point we need some additional structure that will allow us to define categories based on partitions.

\begin{definition}{}{}
Let $f: X \to Y$ be a map. For some partition $P \in \P(Y)$ we define $f^*(P) \in \P(X)$ to be the partition such that
\begin{equation*}
    \forall x,y \in X: x \sim_{f^*(P)} y \iff f(x) \sim_P f(y).
\end{equation*}
We call $f^*(P)$ the \emph{pullback partition of $P$ w.r.t. $f$}.
\end{definition}

Additionally, we can define a partial order on $\P(X)$.

\begin{definition}{}{}
Let $P, Q \in \mathfrak{P}(X)$. Then we write $P \refines Q$ and say that $P$ \emph{refines} $Q$ if
\begin{equation*}
    \forall x,y \in X: x \sim_P y \implies x \sim_Q y.
\end{equation*}
This defines a partial order on $\P(X)$.
\end{definition}
If $f: X \to Y$ is a map, $P \in \P(X)$ and $Q \in \P(Y)$ then we write $P \refines_f Q$ if $P \refines f^*(Q)$. In that case we say that $P$ \emph{refines} $Q$ \emph{via} $f$. A useful fact to remember is that if $\mathrm{id}: X \to X$ is the identity then
\begin{equation}
    \label{eq:refinement_via_identity}
    P \refines_{\mathrm{id}} Q \iff P \refines Q.
\end{equation}

When describing a partition it is often easier to describe a minimal set of conditions the partition relation must satisfy. More formally, we talk about taking the \emph{transitive closure} of these conditions. More formally we have:

\begin{definition}{}{}
    Given a relation $\sim$ on a set $X$ its \emph{transitive closure} is the transitive relation $\sim^+$ such that for $x,y \in X$ we have
    $$
    x \sim^+ y
    $$
    if there exists a sequence $x = x_0, x_1, \dots, x_n = y$ such that $x_i \sim_R x_{i+1}$ for all $i = 0, \dots, n-1$ \cite[p.337]{Lidl1997-kc}.
\end{definition}

In particular, if $\sim$ is reflexive and symmetric then $\sim^+$ is an equivalence relation.
Later we will regularly use this fact by defining equivalence relations as transitive closures of reflexive and symmetric relations.

\begin{definition}{}{}
We say that $P \in \P(X)$ is:
\begin{enumerate}
    \item \emph{discrete} if $x \sim_P y \iff x = y$.
    \item \emph{trivial} if $x \sim_P y$ for all $x,y \in X$.
\end{enumerate}
\end{definition}

Naturally if $Q$ is discrete and $P$ is trivial then $Q \refines R \refines P$ for all $R \in \P(X)$.
Like in chapter \ref{chapter__dataclustering} we also want to consider hierarchical clustering.
For this we introduce the notion of a \emph{dendrogram}.

\begin{definition}{Dendrogram \cite[Def.~2.2]{Carlsson2010}}{dendrogram}
A map $\theta: \R_{\geq0} \to \mathfrak{P}(X)$ with
\begin{enumerate}
    \item $\forall r,s \in \R_{\geq0}: r \leq s \implies  \theta(r) \refines \theta(s)$
    \item $\exists r,s \in \R_{\geq0}$ such that $\theta(r)$ is trivial and $\theta(s)$ is discrete\footnote{In particular, we get that $\theta(0)$ is always discrete.}
    \item $\forall r \in \R_{\geq0} \,\exists \varepsilon > 0$ such that $\theta$ is constant on $[r, r + \varepsilon)$
\end{enumerate}
is called a \emph{dendrogram} of $X$. Sometimes $r$ is referred to as the \emph{scale}.
\end{definition}

This will be familiar to anyone who has seen \emph{persistent homology} where such properties are referred to as \emph{persistence} \cite[Chap.~3]{Carlsson2014}. As an example of a dendrogram consider figure \ref{fig:dendrogram_example}.
\begin{figure}[h]
\centering
\begin{tikzpicture}
    \node (a) at (0,-0.25) {a};
    \node (b) at (1,-0.25) {b};
    \node (c) at (2,-0.25) {c};
    \node (d) at (3,-0.25) {d};
    
    \draw  (a) |- (0.5,0.5);
    \draw  (b) |- (0.5,0.5);

    \draw  (0.5,0.5) |- (1,1.25);
    \draw  (c) |- (1,1.25);


    \draw  (1,1.25) |- (1.5,2);
    \draw (d) |- (1.5,2);

    \draw[dashed]  (1.5,2) -- (1.5,2.5);
    \draw[->, >=stealth] (-0.5,-0.25) -- (-0.5,2.5);

    \draw[dashed] (-0.25, 0.6) -- (3.25, 0.6);
    \draw[color=myred, opacity=0.5, line width=1mm] (-0.2, 0.6) -- (1.2, 0.6);
    \draw[color=myblue, opacity=0.5, line width=1mm] (1.8, 0.6) -- (2.2, 0.6);
    \draw[color=mygreen, opacity=0.5, line width=1mm] (2.8, 0.6) -- (3.2, 0.6);

    \draw[dashed] (-0.25, 1.9) -- (3.25, 1.9);
    \draw[color=mypurple, opacity=0.5, line width=1mm] (-0.2, 1.9) -- (2.2, 1.9);
    \draw[color=mygreen, opacity=0.5, line width=1mm] (2.8, 1.9) -- (3.2, 1.9);

    \draw[] (-0.55, 0.6) -- node[left]{$1$} (-0.45, 0.6);
    \draw[] (-0.55, 1.9) -- node[left]{$2$} (-0.45, 1.9);

    \draw[|->, >=to] (3.35, 0.6) -- (4.25, 0.6);
    \draw[|->, >=to] (3.35, 1.9) -- node[above]{$\theta$} (4.25, 1.9);

    \node[circle,fill=black,inner sep=1pt] (z) at (5, 0.6) {};
    \node[circle,fill=black,inner sep=1pt] (z) at (6, 0.6) {};
    \node[circle,fill=black,inner sep=1pt] (z) at (7, 0.6) {};
    \node[circle,fill=black,inner sep=1pt] (z) at (8, 0.6) {};

    \draw[ellipse, dashed, fill=myred, fill opacity=0.15] (5.5, 0.6) ellipse (0.75 and 0.25);
    \draw[ellipse, dashed, fill=myblue, fill opacity=0.15] (7, 0.6) ellipse (0.25 and 0.25);
    \draw[ellipse, dashed, fill=mygreen, fill opacity=0.15] (8, 0.6) ellipse (0.25 and 0.25);

    \node[circle,fill=black,inner sep=1pt] (z) at (5, 1.9) {};
    \node[circle,fill=black,inner sep=1pt] (z) at (6, 1.9) {};
    \node[circle,fill=black,inner sep=1pt] (z) at (7, 1.9) {};
    \node[circle,fill=black,inner sep=1pt] (z) at (8, 1.9) {};

    \draw[ellipse, dashed, fill=mypurple, fill opacity=0.15] (6, 1.9) ellipse (1.25 and 0.25);
    \draw[ellipse, dashed, fill=mygreen, fill opacity=0.15] (8, 1.9) ellipse (0.25 and 0.25);

    \node (a) at (5,-0.25) {a};
    \node (b) at (6,-0.25) {b};
    \node (c) at (7,-0.25) {c};
    \node (d) at (8,-0.25) {d};

        \node[rotate=90] at (6.5, 1.25) {$\preceq$};
\end{tikzpicture}
\caption{A dendrogram $\theta: \R_{\geq0} \to \P(X)$ with the four points $X = \{a,b,c,d\}$.}
\label{fig:dendrogram_example}
\end{figure}

Notice how in this case the monotonicity condition is satisfied \eg\ $\theta(1) \refines \theta(2)$ as shown on the righthand side. The second condition of a dendrogram is also met as it becomes trivial at the top and discrete at the bottom. Finally, the third condition tells us what value the dendrogram takes whenever a ``merge happens''. As for the relevance of the last condition, consider the following remark.

\begin{myremark}{}{regularity_of_dendrograms}
\todo[unify all these remarks about regularity]
Concerning the third condition of dendrograms, since all our metric spaces are finite, we could decide to omit it in the definition of a dendrogram. Dendrograms would still have discrete scale \ie\ the dendrogram would still be constant on intervals.
However, it would not be clear what value the dendrogram would take at the endpoints of these intervals\footnote{There are other ways we could decide to fix this issue. \Eg\ we could consider equivalence relations of dendrograms.}.
This technicallity will become important for some uniqueness theorems we present later.
\end{myremark}

We can finally define the categories which will be the ``outputs'' of clustering functors.

\begin{definition}{\cite[Def.~3.2]{Carlsson2010}}{output_classical_clustering_functors}
The category $\C$ of \emph{outputs of classical clustering functors} is defined by
\begin{equation*}
    \ob(\C) := \{(X, P): X \text{ a finite set and } P \in \P(X)\}
\end{equation*}
and for all $(X,P), (Y,Q) \in \ob(\C)$ we have the morphisms
\begin{equation*}
    \mor_\C((X,P), (Y,Q)) := \{f: X \to Y: P \refines_f Q\}.
\end{equation*}
In short, we write $(X,P) \refines_f (Y,Q)$ for such a morphism. As before, the composition is given by composition of maps and the identity is the identity map.
\end{definition}

\begin{definition}{\cite[Def.~3.3]{Carlsson2010}}{output_hierarchical_clustering_functors}
Similarly, we define the category $\H$ of \emph{outputs of hierarchical clustering functors}, given by
\begin{equation*}
    \ob(\H) := \{(X, \theta_X): X \text{ a finite set and } \theta_X: \R_{\geq0} \to \P(X) \ \text{a dendrogram}\}
\end{equation*}
and for all $(X, \theta_X), (Y, \theta_Y) \in \ob(\H)$ we have the morphisms
\begin{equation*}
    \mor_\H((X, \theta_X), (Y,\theta_Y)) :=
    \left\{f: X \to Y: \forall r \in \R_{\geq0}: \theta_X(r) \refines_f \theta_Y(r)) \right\}.
\end{equation*}
Again, we write $(X, \theta_X) \refines_f (Y, \theta_Y)$ for such a morphism, and the composition and identity are defined as before.
\end{definition}

Another way of thinking about morphisms in $\C$ (or $\H$) is that given $(X,P), (Y,Q) \in \ob(\C)$ a morphism $f \in \mor_\C((X,P), (Y,Q))$ is simply a map $f: X \to Y$ such that
$$
\forall x,y \in X: x \sim_P y \implies f(x) \sim_Q f(y).
$$

\begin{definition}{}{shift_functor}
We define the \emph{shift} functor $\sigma_\lambda: \H \to \H$ for some $\lambda > 0$. Given $(X, \theta_X) \in \ob(\H)$ we set
$$
\sigma_\lambda(X, \theta_X(r)) := (X, \theta_X(r \cdot \lambda)) \quad \forall r \in \R_{\geq0}.
$$
By checking the condition on morphisms in definition \ref{def:output_hierarchical_clustering_functors}, we see that this induces a functor.

\todo[check if this is correct; take reciprocal?]
\end{definition}

\section{Clustering Functors}
\begin{definition}{Clustering Functor \cite[Sec.~4.1]{Carlsson2010}}{}
Let $\M \in \{\iso, \inj, \gen\}$ and $\A \in \{\C, \H\}$. An $\M$-\emph{functorial clustering functor} (or $\M$ \emph{clustering functor}) is a functor from $\M$ to $\A$
$$\Cf : \M \longrightarrow \A$$
such that $\Cf$ factorizes the forgetful functors (see \ref{not:factorizing_forgetful_functor}). If $\A = \C$ we say that $\Cf$ is \emph{classical} and otherwise if $\A = \H$ we say it is \emph{hierarchical}.
\end{definition}

We can express the functoriality of a clustering functor $\Cf$ by the following commutative diagram:

\begin{equation*}
    \begin{tikzcd}
    {(X,d)} \arrow[r, "f"] \arrow[d, "\Cf", Rightarrow] & {(Y,d)} \arrow[d, "\Cf", Rightarrow] \\
    {\Cf(X,d)} \arrow[r, "\refines_f"]                  & {\Cf(Y,d)}
    \end{tikzcd}
\end{equation*}

For a hierarchical clustering functor $\Hf$ we will use the simplified notation:
$$
\Hf(X,d;r) := (X,\theta_X(r)).
$$
Moreover, for any $r \in \R_{\geq0}$ a hierarchical clustering functor $\Hf$ induces a classical clustering functor $\Hf(\ \cdot \ ;r)$.

\begin{myremark}{}{induced_functor_by_inclusion}
Recall the inclusions \eqref{eq:inclusions_of_finite_metric_space_categories} and their induced functors.
Given a clustering functor on a larger category, say $\Cf: \gen \to \C$, this immediately induces clustering functors on the smaller categories by pre-composition with the inclusion functors $\iso \to \inj \to \gen$. We will use the same symbol for the induced functors.
\end{myremark}

With this in mind, it makes sense to think of the categories $\iso, \inj, \gen$ as being different levels of \emph{structure} a clustering functor can \emph{preserve} where $\iso$ is the least restrictive and $\gen$ the most restrictive.


\begin{myremark}{}{}
We can extend the partial order $\refines$ on $\P(X)$ to a partial order on clustering functors.
In particular, if $\Cf, \mathfrak{D}: \M \to \C$ are classical clustering functors we write $\Cf \refines \mathfrak{D}$ if
\begin{equation*}
    \forall (X,d) \in \ob(\M): \Cf(X,d) \refines \mathfrak{D}(X,d).
\end{equation*}
And in case of hierarchical clustering functors $\Cf, \mathfrak{D}: \M \to \H$ we write $\Cf \refines \mathfrak{D}$ if
\begin{equation*}
    \forall (X,d) \in \ob(\M) \, \forall r \in \R_{\geq0}: \Cf(X,d;r) \refines \mathfrak{D}(X,d;r).
\end{equation*}
\end{myremark}